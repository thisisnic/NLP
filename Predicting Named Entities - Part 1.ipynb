{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Work in Progress)\n",
    "\n",
    "The data examined here comes from: https://github.com/aritter/twitter_nlp/blob/master/data/annotated/ner.txt\n",
    "\n",
    "It is an annotated dataset of tweets often used for named-entity recognition tasks.\n",
    "\n",
    "I am going to examine a few methods used for named entity recognition, and compare their success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>@paulwalk</th>\n",
       "      <th>O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'s</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>view</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>from</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43486</th>\n",
       "      <td>come</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43487</th>\n",
       "      <td>get</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43488</th>\n",
       "      <td>some</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43489</th>\n",
       "      <td>grub</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43490</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43491 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      @paulwalk    O\n",
       "0            It    O\n",
       "1            's    O\n",
       "2           the    O\n",
       "3          view    O\n",
       "4          from    O\n",
       "...         ...  ...\n",
       "43486      come    O\n",
       "43487       get    O\n",
       "43488      some    O\n",
       "43489      grub    O\n",
       "43490       NaN  NaN\n",
       "\n",
       "[43491 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data/ritter.txt\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@paulwalk\tO\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "f = open(\"data/ritter.txt\", \"r\")\n",
    "print(f.readline()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@paulwalk\\tO\\n', 'It\\tO\\n', \"'s\\tO\\n\", 'the\\tO\\n', 'view\\tO\\n', 'from\\tO\\n', 'where\\tO\\n', 'I\\tO\\n', \"'m\\tO\\n\", 'living\\tO\\n', 'for\\tO\\n', 'two\\tO\\n', 'weeks\\tO\\n', '.\\tO\\n', 'Empire\\tB-facility\\n']\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "f = open(\"data/ritter.txt\", \"r\")\n",
    "print(f.readlines(100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we'll read in the data as word/tag pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "this_tweet = []\n",
    "with open('data/ritter.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        if line == \"\\t\\n\":\n",
    "            tweets.append(this_tweet)\n",
    "            this_tweet = []\n",
    "        else:\n",
    "            parts = line.split(\"\\t\")\n",
    "            word = parts[0]\n",
    "            tag = parts[1].replace(\"\\n\", \"\")\n",
    "            this_tweet.append((word, tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('@paulwalk', 'O'),\n",
       " ('It', 'O'),\n",
       " (\"'s\", 'O'),\n",
       " ('the', 'O'),\n",
       " ('view', 'O'),\n",
       " ('from', 'O'),\n",
       " ('where', 'O'),\n",
       " ('I', 'O'),\n",
       " (\"'m\", 'O'),\n",
       " ('living', 'O'),\n",
       " ('for', 'O'),\n",
       " ('two', 'O'),\n",
       " ('weeks', 'O'),\n",
       " ('.', 'O'),\n",
       " ('Empire', 'B-facility'),\n",
       " ('State', 'I-facility'),\n",
       " ('Building', 'I-facility'),\n",
       " ('=', 'O'),\n",
       " ('ESB', 'B-facility'),\n",
       " ('.', 'O'),\n",
       " ('Pretty', 'O'),\n",
       " ('bad', 'O'),\n",
       " ('storm', 'O'),\n",
       " ('here', 'O'),\n",
       " ('last', 'O'),\n",
       " ('evening', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2394"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to divide the tweets into a train/dev/test split.  We'll go for a 60/20/20 split as the dataset isn't huge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1436"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "train_indices = random.sample(range(0,len(tweets)), round((len(tweets)*0.6)))\n",
    "training_set = [tweets[i] for i in train_indices]\n",
    "len(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_indices = [i for i in range(0,len(tweets)) if i not in train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_indices = random.sample(remaining_indices, round((len(remaining_indices)*0.5)))\n",
    "dev_set = [tweets[i] for i in dev_indices]\n",
    "len(dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_indices = [i for i in remaining_indices if i not in dev_indices]\n",
    "test_set = [tweets[i] for i in test_indices]\n",
    "len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to define some features for our dataset.  For the sake of simplicity we'll use these functions from the CRFsuite documentation.  Due to the format of the input data, I've removed the features relating to the POS tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit()\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper()\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper()\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in training_set]\n",
    "y_train = [sent2labels(s) for s in training_set]\n",
    "\n",
    "X_dev = [sent2features(s) for s in dev_set]\n",
    "y_dev = [sent2labels(s) for s in dev_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The beauty of the CRF model is that it is able to use surrounding predictions to help guide the current prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn_crfsuite\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-company',\n",
       " 'B-tvshow',\n",
       " 'I-tvshow',\n",
       " 'B-geo-loc',\n",
       " 'B-other',\n",
       " 'I-other',\n",
       " 'B-facility',\n",
       " 'I-facility',\n",
       " 'I-geo-loc',\n",
       " 'B-person',\n",
       " 'I-person',\n",
       " 'B-product',\n",
       " 'B-sportsteam',\n",
       " 'I-sportsteam',\n",
       " 'I-product',\n",
       " 'B-musicartist',\n",
       " 'I-musicartist',\n",
       " 'I-company',\n",
       " 'B-movie',\n",
       " 'I-movie']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3062546237485865"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn_crfsuite import metrics\n",
    "y_pred = crf.predict(X_dev)\n",
    "metrics.flat_f1_score(y_dev, y_pred,\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "    B-company      0.923     0.364     0.522        33\n",
      "    I-company      0.000     0.000     0.000         9\n",
      "   B-facility      0.533     0.276     0.364        29\n",
      "   I-facility      0.588     0.323     0.417        31\n",
      "    B-geo-loc      0.682     0.283     0.400        53\n",
      "    I-geo-loc      0.000     0.000     0.000        10\n",
      "      B-movie      1.000     0.167     0.286         6\n",
      "      I-movie      1.000     0.083     0.154        12\n",
      "B-musicartist      1.000     0.182     0.308        11\n",
      "I-musicartist      1.000     0.167     0.286        12\n",
      "      B-other      0.167     0.068     0.097        44\n",
      "      I-other      0.074     0.082     0.078        49\n",
      "     B-person      0.615     0.369     0.462        65\n",
      "     I-person      0.520     0.481     0.500        27\n",
      "    B-product      0.714     0.227     0.345        22\n",
      "    I-product      0.667     0.222     0.333        18\n",
      " B-sportsteam      0.500     0.111     0.182         9\n",
      " I-sportsteam      0.000     0.000     0.000         4\n",
      "     B-tvshow      0.000     0.000     0.000         5\n",
      "     I-tvshow      0.000     0.000     0.000         5\n",
      "\n",
      "    micro avg      0.463     0.231     0.308       454\n",
      "    macro avg      0.499     0.170     0.237       454\n",
      " weighted avg      0.525     0.231     0.306       454\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\will\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_dev, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model fit isn't amazing here, and it looks like leaving out the POS tag isn't going to help with model fit.  In Part 2, I will use spaCy to help craft better features and improve my predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(training_set, open( \"training_set.p\", \"wb\"))\n",
    "pickle.dump(dev_set, open( \"dev_set.p\", \"wb\"))\n",
    "pickle.dump(test_set, open( \"test_set.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
